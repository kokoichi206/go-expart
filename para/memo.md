## 並行処理入門

### ムーアの法則
ムーアの法則：1975~2012

> 集積回路内のコンポーエントの数は2年で２倍になる！

ムーアの法則の限界を迎えるにあたり、マルチコアプロセッサーが必要に迫られて誕生。

アムダールの法則：

> プログラムの何割を並列化できないかによって、並列化による性能向上の限界が決まる

Spigotアルゴリズムという、πの数値計算

水平方向へのスケーリングは 2000 年代初頭にクラウドコンピューティングという新たなパラダイムが根付いたことで、より簡単になった。

マルチコアプロセッサー、クラウドコンピューティグ、Webスケール、そして相対する課題が並列可能かどうかの見極め。

#### The free lunch is over.
これまではシングルコアの性能向上に応じてソフトウェアの性能も向上していたので、プログラマはただ飯喰いをしているようなものだったが、マルチコアの時代に入ってそうは行かなくなった。

### なぜ並行処理が難しいのか

#### 競合状態
２つ以上の操作が正しい順序で実行されなければいけないところで、プログラムが順序を保証するように書かれていなかった時に発生する。

大抵の場合は、**データ競合**。ある並行処理の操作が変数を読み込もうとしている時に、他の並行処理の操作が不確定のタイミングで同じ変数に書き込みを行おうとすると発生する。

sleep を入れても根本的解決にはならず、データ競合が起きにくくなっただけ。常に論理的正当性を目指すべき！！！


#### アトミック性
何かがアトミック、アトミック性があると考えられる場合、それが操作されている特定のコンテキストの中では分割不能、あるいは中断不可であることを意味する。

ある操作のアトミック性というのは、現在注目しているスコープに強く依存する！！

#### メモリアクセス同期
プログラム内のクリティカルセクションを守る方法はいくつかあり、解決策の１つはクリティカルセクション間でメモリへのアクセスを同期すること。

メモリへの動機的アクセスは、注意しないとパフォーマンスに悪影響になる。

#### デッドロック、ライブロック、リソース枯渇

##### デッドロック
全ての並行なプロセスがお互いの処理を待ち合っている状況。

##### ライブロック
ライブロックとは並行操作をおこなっているけど、その操作はプログラムの状態を全く進めていないプログラムのこと。

廊下ですれ違う時に、相手の避けようとした方に自分も避けてしまう。

ライブロックはデッドロックよりも見つけるのが難しい。それは、プログラムが動いているように見えるから！そして、ライブロックはリソース枯渇と呼ばれるより大きな問題の一部。

##### リソース枯渇
並行プロセスが仕事をするのに必要なリソースを取得できない状況。

ライブロックの際に、各ゴルーチンで枯渇していたリソースは共有ロックだった。

リソース枯渇を検知して解決する良い方法の１つは、仕事が終わったらログを出力して、仕事の速度が期待通りになっているかを測定すること！

リソース枯渇はCPU、メモリ、ファイルハンドラー、DB接続といったものにも適応される

#### 並行処理の安全性
全てのコードの裏では最低一人の人間が関わっている。

抽象化を適切な水準で行うのは難しい。呼び出し元にどの程度まで並行処理をさらすのか。

以下のコメントがコードにあると嬉しい

- 誰が並行処理を担っているか
- 問題空間がどのように並行処理のプリミティブに対応しているか
- 誰が問題処理を担っているか

### 簡潔さ
Goは、ガベージコレクションの停止時間が短い！！（10~100 μ秒）

10 μs の停止時間を気にする必要がないのであれば、Goは並行プロセスにわたってのメモリ管理はもちろん、一切のメモリ管理を強制することなく、並行処理をずっと簡単に使えるようにしてくれる。


## 並行性をどうモデル化するか：CSP

### 並行性と並列性
> 並行性はコードの性質を指し、並列性は動作しているプログラムの性質をさす。

並列なコードを書いているのではなく、並列に走ってほしいと思うコードを書いているだけ！並列性はプログラムのランタイムの性質であって、コードの性質ではない。

CPUなどの、プログラムの設計の下にある抽象化層によって、並列性と並行性が区別できるようになっている。

並列性は、時間やコンテキストの機能である。

抽象化のスタックを下にいくにつれて、物事を並行に構成する上での問題は、論理的に考えることがより難しく、かつより重要になってくる。

Goが公開される以前、たいていの有名なプログラミング言語ではOSのスレッドが何層にも連鎖する抽象化の最終地点だった。並行処理のコードを書きたければ、プログラムのスレッドに合わせて書いて、スレッド間でメモリへのアクセスを同期するという書き方をしていた。

Goではこの（抽象化の）連鎖の中に新たなリンクを追加した。それが**ゴルーチン（goroutine）**。また、**チャネル（channel）**という新たなプリミティブを導入している。

### CSP: Communicating Sequential Processes
CSPはGoの成功理由として、あるいは並行プログラミングの万能薬として称賛される。CSPは物事を簡単にする一方で、プログラムをより堅牢にしてくれる！！！

CSPは「Communicationg Sequential Processes」の略で、手法とそれを紹介した論文のタイトルの両方を指す。

入力と出力は言語のプリミティブと考える必要がある！CSPプログラミング言語では正確なプロセス間の入出力、別の言い方では通信を構成するプリミティブが含まれていた。この意味では**プロセス**という用語は、必要な入力を処理し、他のプロセスが消費する出力をもたらすロジックの塊をカプセル化するものとして定義できる。

GoはCSPの原理を言語の中核として具現化し、この形式の並行プログラミングを大衆にもたらした最初の言語の一つ！！

### Goの強み
並行処理の問題を解決するものを設計する際には、言語の一連の抽象化がOSスレッドとメモリアクセス動機の水準にとどまってしまうのが一般的。Goでは異なる手法を採用し、代わりにゴルーチンとチャネルという概念を用意した。

並行プログラムの抽象化における従来の手法とGoでの手法の２つを比較するならば、おそらくゴルーチンとスレッドを、チャネルとミューテックスを比較することになる（偶然似ているだけ）

より自然にコードを問題空間に対応させられる。

GoのランタイムはごルーチンをOSスレッドに自動的にマルチプレキシングし、そのスケジューリングもしてくれる。つまり、設計を変更することなしに、ランタイムの最適化が行われる！

### Goの並行処理における哲学
プログラムを書く際にはある瞬間にただ１つのゴルーチンがある特定のデータの責任を持つように心がける。メモリを共有することで通信するのではなく、かわりに、通信することでメモリを共有する！

簡潔さを求め、チャネルをできる限り使い、ゴルーチンを湯水のように使うこと！


